{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bX85AILBAoTL",
    "outputId": "e6558e91-133e-414b-9ceb-9865d83d1740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (4.26.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (4.12.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.1)\n",
      "Requirement already satisfied: trio~=0.17 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from selenium) (2024.2.2)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from trio~=0.17->selenium) (23.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.6)\n",
      "Requirement already satisfied: outcome in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /opt/homebrew/Caskroom/miniforge/base/envs/proj/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "zQmLv3C_qDRc",
    "outputId": "4593b325-20fe-4591-f975-8aa36817fc85"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "\n",
    "import re\n",
    "\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "from typing import List\n",
    "\n",
    "# place_id = \"ChIJ8TuKLOqrQjQRSrGsTe4tu2o\"\n",
    "# place_name = \"Remember Me_記得我．café\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import json\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import os.path\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class GoogleCrawler():\n",
    "    def __init__(self):\n",
    "        self.api_key = \"AIzaSyCaXrjbbXaw_s0HJHQi8wJp19QSKL8qMP4\"\n",
    "        self.file_path = \"./top20_cafes.json\"\n",
    "        # 設置最大評論數量\n",
    "        self.MAX_LEN = 100\n",
    "        self.driver = None\n",
    "        self.options = Options()\n",
    "        self.options.add_argument(\"-headless\") \n",
    "\n",
    "    def create_empty_json(self):\n",
    "        data = {}\n",
    "        data[\"places\"] = []\n",
    "        # 建立json檔\n",
    "        with open(self.file_path, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "    \n",
    "    def get_all_cafe_by_map(self, query: str = \"台北市的咖啡廳\") -> List[str]:\n",
    "        warnings.warn(\n",
    "            \"deprecated_method() is deprecated and will be removed in a future version. \"\n",
    "            \"Use new_method() instead.\",\n",
    "            DeprecationWarning,\n",
    "            stacklevel=2\n",
    "        )\n",
    "        # 咖啡廳數量\n",
    "        cafe_count = 1500\n",
    "        url = \"https://www.google.com/maps/search/\" + query\n",
    "        self.driver = webdriver.Firefox()\n",
    "        self.driver.get(url)\n",
    "        wait = WebDriverWait(self.driver, 20)  # 增加等待時間\n",
    "        # 滾動整個結果區\n",
    "        try:\n",
    "            pane = wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"m6QErb DxyBCb kA9KIf dS8AEf XiKgde ecceSd\"]')))\n",
    "            for i in range(int(int(cafe_count) / 10)-1):\n",
    "                print(i)\n",
    "                self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", pane)\n",
    "                time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(\"無法找到評論面板:\", e)\n",
    "        #\n",
    "        results = self.driver.find_elements(By.XPATH,f'//a[@class=\"hfpxzc\"]')\n",
    "        return[r.get_attribute('href') for r in results]\n",
    "        self.driver.quit()\n",
    "        self.driver = None\n",
    "\n",
    "    def get_all_cafe(self, url: str = \"https://cafenomad.tw/taipei/list\"):\n",
    "        self.driver = webdriver.Firefox(options=self.options)\n",
    "        self.driver.get(url)\n",
    "        links = self.driver.find_elements(By.XPATH,f'//a[@class=\"seo-link\"]')\n",
    "        results = set([r.text for r in links if \"暫停營業\" not in r.text])\n",
    "        data = {}\n",
    "        print(len(results))\n",
    "        with open(self.file_path, \"w\") as f:\n",
    "            data = {\n",
    "                \"places\": [{\"name\": name} for name in results]\n",
    "            }\n",
    "            json.dump(data, f,  ensure_ascii=False,indent=4)\n",
    "        self.driver.quit()\n",
    "        self.driver = None\n",
    "\n",
    "    def fetch_all_cafe_gmap_data(self):\n",
    "        self.driver = webdriver.Firefox()\n",
    "\n",
    "        # 讀取原始 JSON 資料\n",
    "        with open(self.file_path, \"r\") as file:      \n",
    "            data = json.load(file)\n",
    "        # 保留原始資料\n",
    "        original_places = data.get(\"places\", [])\n",
    "        \n",
    "        # 初始化更新後的資料列表\n",
    "        updated_places = original_places[:]\n",
    "\n",
    "        for idx, place in enumerate(original_places, start=1):\n",
    "            # 如果資料中已經有，跳過處理\n",
    "            if \"address\" in place and place[\"address\"]:\n",
    "                continue\n",
    "            if \"rating\" in place and place[\"rating\"]:\n",
    "                continue\n",
    "            \n",
    "            # 獲取新的 gmap 資料\n",
    "            gmap_data = self.get_gmap_data(place[\"name\"])\n",
    "            if gmap_data is None:\n",
    "                continue\n",
    "            \n",
    "            # 更新當前的 place\n",
    "            place.update(gmap_data)\n",
    "\n",
    "            # 每完成 10 個或處理完最後一個，寫回 JSON\n",
    "            if idx % 10 == 0 or idx == len(original_places):\n",
    "                with open(self.file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                    json.dump({\"places\": updated_places}, f, ensure_ascii=False, indent=4)\n",
    "                print(f\"Written {idx} places to {self.file_path}\")\n",
    "        \n",
    "        self.driver.quit()\n",
    "        self.driver = None\n",
    "\n",
    "    def get_gmap_data(self, name: str):\n",
    "        if self.driver == None:\n",
    "            self.driver = webdriver.Firefox()\n",
    "        data = {\n",
    "            \"name\": name,\n",
    "            \"gmap_link\": \"\",\n",
    "            \"rating\": 0,\n",
    "            \"address\": \"\",\n",
    "            \"phone\": \"\",\n",
    "            \"reviews\": [],\n",
    "            \"business_hours\": {}\n",
    "        }\n",
    "        url = f\"https://www.google.com/maps/search/{name}/data=!3m1!4b1?entry=ttu&g_ep=EgoyMDI0MTExNy4wIKXMDSoASAFQAw%3D%3D\"\n",
    "        self.driver.get(url)\n",
    "        sleep(1)\n",
    "        wait = WebDriverWait(self.driver, 3)\n",
    "        elements = self.driver.find_elements(By.CSS_SELECTOR, \"div.Q2vNVc.fontHeadlineSmall\")\n",
    "        for element in elements:\n",
    "            # 檢查文字內容是否包含「找不到」\n",
    "            if \"找不到\" in element.text:\n",
    "                print(f\"Location not found message detected: {element.text}\")\n",
    "                return None\n",
    "        if len(self.driver.find_elements(By.XPATH, f'//div[@class=\"m6QErb DxyBCb kA9KIf dS8AEf XiKgde ecceSd\"]')) != 0:\n",
    "            # 如果多於一個選項會出現結果選項，而不會直接跳轉到店家頁面\n",
    "            results = self.driver.find_elements(By.XPATH,f'//a[@class=\"hfpxzc\"]')\n",
    "            if len(results) == 0:\n",
    "                return None\n",
    "            gmap_link = results[0].get_attribute('href')\n",
    "            self.driver.get(gmap_link)\n",
    "            data[\"gmap_link\"] = gmap_link\n",
    "        sleep(1)\n",
    "        # 點擊顯示營業時間\n",
    "        try:\n",
    "            show_business_hour_button = self.driver.find_element(By.CSS_SELECTOR, \"span.puWIL.hKrmvd.google-symbols.OazX1c[aria-label='顯示本週營業時間']\")\n",
    "            if show_business_hour_button:\n",
    "                show_business_hour_button.click()\n",
    "        except NoSuchElementException:\n",
    "            print(\"Show business hour button not found.\")\n",
    "        # 評分\n",
    "        try:\n",
    "            rating_element = self.driver.find_element(By.CSS_SELECTOR, 'div.F7nice > span > span[aria-hidden=\"true\"]')\n",
    "            if rating_element:\n",
    "                data[\"rating\"] = rating_element.text\n",
    "        except NoSuchElementException:\n",
    "            print(\"Show rating not found.\")\n",
    "        # 地址\n",
    "        try:\n",
    "            address_button_element = self.driver.find_element(By.CSS_SELECTOR, 'button.CsEnBe[aria-label^=\"地址\"]')\n",
    "            if address_button_element:\n",
    "                aria_label = address_button_element.get_attribute(\"aria-label\")\n",
    "                address = aria_label.split(\": \")[-1]\n",
    "                data[\"address\"] = address\n",
    "        except NoSuchElementException:\n",
    "            print(\"address button not found.\")\n",
    "        # phone\n",
    "        try:\n",
    "            phone_button_element = self.driver.find_element(By.CSS_SELECTOR, 'button.CsEnBe[aria-label^=\"電話號碼\"]')\n",
    "            if phone_button_element:\n",
    "                phone_number = phone_button_element.get_attribute(\"aria-label\").split(\": \")[-1]\n",
    "                data[\"phone\"] = phone_number\n",
    "        except NoSuchElementException:\n",
    "            print(\"phone button not found.\")\n",
    "        # 營業時間\n",
    "        # 建立存放營業時間的字典\n",
    "        business_hours = {}\n",
    "        rows = self.driver.find_elements(By.CSS_SELECTOR, \"table.eK4R0e tbody tr\")\n",
    "        for row in rows:\n",
    "            day_element = row.find_element(By.CSS_SELECTOR, \"td.ylH6lf > div\")\n",
    "            hours_element = row.find_element(By.CSS_SELECTOR, \"td.mxowUb ul li\")\n",
    "            day = day_element.text.strip()  # 取得星期\n",
    "            hours = hours_element.text.strip()  # 取得時間\n",
    "            business_hours[day] = hours\n",
    "        data[\"business_hours\"] = business_hours\n",
    "        # 點擊評論頁按鈕，切換到這頁÷\n",
    "        review_button = None\n",
    "        max_attempts = 3\n",
    "        for attempt in range(max_attempts):\n",
    "            try:\n",
    "                review_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[role='tab'][aria-label*='的評論']\")))\n",
    "                review_button.click()\n",
    "                sleep(2)\n",
    "                break  # 成功點擊，跳出迴圈\n",
    "            except TimeoutException:\n",
    "                print(f\"Review button not found on attempt {attempt + 1}. Refreshing...\")\n",
    "                self.driver.refresh()\n",
    "        if review_button is None:\n",
    "            print(\"Review button could not be found after retries.\")\n",
    "            return data\n",
    "        reviews = self._get_all_reviews_of_cafe()\n",
    "        data[\"reviews\"] = reviews\n",
    "        return data\n",
    "\n",
    "    \n",
    "    def _get_all_reviews_of_cafe(self):\n",
    "        if self.driver == None:\n",
    "            print(\"driver not init\")\n",
    "        wait = WebDriverWait(self.driver, 3)\n",
    "        try:\n",
    "            review_num_label = wait.until(EC.visibility_of_element_located((By.XPATH, '//div[@class=\"jANrlb \"][1]//div[@class=\"fontBodySmall\"]')))\n",
    "            time.sleep(1)  # 額外等待\n",
    "            review_num_text = review_num_label.text.split(\" \")[0]\n",
    "            review_num = int(review_num_text.replace(\",\", \"\")) if review_num_text else 0\n",
    "            review_num = min(review_num, self.MAX_LEN)\n",
    "            print(review_num)\n",
    "        except ValueError:\n",
    "            print(\"評論數量無法轉換為整數，請檢查XPATH或等待時間。\")\n",
    "        except Exception as e:\n",
    "            print(\"發生其他錯誤:\", e)\n",
    "        # 滾動評論面板\n",
    "        try:\n",
    "            pane = wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"m6QErb DxyBCb kA9KIf dS8AEf XiKgde \"]')))\n",
    "            for i in range(int(int(review_num) / 10)-1):\n",
    "                self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", pane)\n",
    "                time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(\"無法找到評論面板:\", e)\n",
    "\n",
    "        full_btns = self.driver.find_elements(By.XPATH, f'//button[@class=\"w8nwRe kyuRq\"]')\n",
    "        for btn in full_btns:\n",
    "            btn.click()\n",
    "        # 抓取評論區塊\n",
    "        reviewDivs = self.driver.find_elements(By.XPATH, \"//div[@class='jftiEf fontBodyMedium ']\")\n",
    "        all_reviews = []\n",
    "        sleep(1.5)\n",
    "        for review in reviewDivs:\n",
    "            # review_text不一定有\n",
    "            try:\n",
    "                review_text = review.find_element(By.CLASS_NAME, 'MyEned').text\n",
    "            except:\n",
    "                print(\"no review text\")\n",
    "                review_text = \"\"\n",
    "            try:\n",
    "                rating = review.find_element(By.CLASS_NAME,'kvMYJc').get_attribute('aria-label')\n",
    "            except:\n",
    "                print(\"no rating\")\n",
    "                rating = \"-1\"\n",
    "            try:\n",
    "                review_date =  review.find_element(By.CLASS_NAME,'rsqaWe').text\n",
    "            except:\n",
    "                print(\"no date\")\n",
    "                review_date = \"\"\n",
    "            all_reviews.append(\n",
    "                {\n",
    "                    \"reviewer\": review.find_element(By.CLASS_NAME,'d4r55 ').text,\n",
    "                    \"rating\": rating,\n",
    "                    \"reviewed_date\": review_date,\n",
    "                    \"review_text\": review_text\n",
    "                })\n",
    "            \n",
    "        return all_reviews\n",
    "    \n",
    "    def _navigate_to_cafe_page(self, name: str):\n",
    "        url = f\"https://www.google.com/maps/search/{name}\"\n",
    "        self.driver.get(url)\n",
    "        sleep(1)\n",
    "        wait = WebDriverWait(self.driver, 3)\n",
    "        elements = self.driver.find_elements(By.CSS_SELECTOR, \"div.Q2vNVc.fontHeadlineSmall\")\n",
    "        for element in elements:\n",
    "            # 檢查文字內容是否包含「找不到」\n",
    "            if \"找不到\" in element.text:\n",
    "                print(f\"Location not found message detected: {element.text}\")\n",
    "                return None\n",
    "        if len(self.driver.find_elements(By.XPATH, f'//div[@class=\"m6QErb DxyBCb kA9KIf dS8AEf XiKgde ecceSd\"]')) != 0:\n",
    "            # 如果多於一個選項會出現結果選項，而不會直接跳轉到店家頁面\n",
    "            results = self.driver.find_elements(By.XPATH,f'//a[@class=\"hfpxzc\"]')\n",
    "            if len(results) == 0:\n",
    "                return self.driver.current_url\n",
    "            gmap_link = results[0].get_attribute('href')\n",
    "            self.driver.get(gmap_link)\n",
    "            return gmap_link\n",
    "    \n",
    "    def _get_latlong_of_cafe(self, url):\n",
    "        match = re.search(r\"@([\\d.,\\-]+)\", url)\n",
    "        if match:\n",
    "            coordinates = match.group(1)\n",
    "            return coordinates\n",
    "        return \"-1, -1,\"\n",
    "    \n",
    "    def add_latlong_to_json(self):\n",
    "        if self.driver is None:\n",
    "            self.driver = webdriver.Firefox()\n",
    "        \n",
    "        with open(self.file_path, \"r\") as file:\n",
    "            data = json.load(file)\n",
    "        places = data[\"places\"]\n",
    "        count = 0\n",
    "        with tqdm(total=len(places), desc=\"Processing places\", unit=\"place\") as pbar:\n",
    "            for place in places:\n",
    "                # 跳過已處理的條目\n",
    "                # if \"latitude\" in place and \"longitude\" in place:\n",
    "                #     print(\"skip\")\n",
    "                #     continue\n",
    "                \n",
    "                link = self._navigate_to_cafe_page(place[\"name\"])\n",
    "\n",
    "                sleep(5)\n",
    "                coor = self._get_latlong_of_cafe(self.driver.current_url)\n",
    "                latitude, longitude, _ = coor.split(',')\n",
    "                print(coor)\n",
    "                place[\"latitude\"] = latitude\n",
    "                place[\"longitude\"] = longitude\n",
    "            \n",
    "                count += 1\n",
    "                pbar.update(1)\n",
    "                # 每 100 次將進度保存到文件\n",
    "                if count % 10 == 0:\n",
    "                    with open(self.file_path, \"w\") as file:\n",
    "                        json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "                    print(f\"Progress saved: {count} places updated.\")\n",
    "            \n",
    "            # 處理完所有條目後再次保存\n",
    "            with open(self.file_path, \"w\") as file:\n",
    "                json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "            print(\"All places updated and saved.\")\n",
    "\n",
    "        self.driver.quit()\n",
    "        self.driver = None\n",
    "crawler = GoogleCrawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:   5%|▌         | 1/20 [00:08<02:32,  8.02s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0329519,121.5505806,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  10%|█         | 2/20 [00:15<02:22,  7.91s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0422129,121.5630112,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  15%|█▌        | 3/20 [00:23<02:13,  7.88s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0363927,121.5462741,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  20%|██        | 4/20 [00:31<02:05,  7.81s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0318139,121.5447918,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  25%|██▌       | 5/20 [00:39<01:57,  7.86s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0754559,121.5760439,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  30%|███       | 6/20 [00:47<01:49,  7.80s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0300256,121.5306174,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  35%|███▌      | 7/20 [00:54<01:41,  7.79s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0209198,121.5316901,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  40%|████      | 8/20 [01:03<01:36,  8.01s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0504557,121.5352787,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  45%|████▌     | 9/20 [01:10<01:26,  7.87s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0527904,121.5392235,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  50%|█████     | 10/20 [01:18<01:16,  7.68s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0262375,121.5474209,17\n",
      "Progress saved: 10 places updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  55%|█████▌    | 11/20 [01:26<01:10,  7.86s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.038977,121.5559262,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  60%|██████    | 12/20 [01:33<01:01,  7.74s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0386537,121.5418983,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  65%|██████▌   | 13/20 [01:41<00:54,  7.76s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0545945,121.521935,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  70%|███████   | 14/20 [01:49<00:46,  7.67s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0702883,121.588293,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  75%|███████▌  | 15/20 [01:56<00:38,  7.71s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.079425,121.546087,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  80%|████████  | 16/20 [02:04<00:31,  7.76s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.044403,121.5159776,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  85%|████████▌ | 17/20 [02:12<00:23,  7.82s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0235003,121.5436548,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  90%|█████████ | 18/20 [02:20<00:15,  7.71s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0206288,121.5329411,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places:  95%|█████████▌| 19/20 [02:27<00:07,  7.68s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0503626,121.5617335,17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing places: 100%|██████████| 20/20 [02:35<00:00,  7.76s/place]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.0576079,121.551816,17\n",
      "Progress saved: 20 places updated.\n",
      "All places updated and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "crawler.add_latlong_to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawler.get_all_cafe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawler.fetch_all_cafe_gmap_data()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4ecZ42R-6xsv"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
