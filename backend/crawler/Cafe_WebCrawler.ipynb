{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bX85AILBAoTL",
    "outputId": "e6558e91-133e-414b-9ceb-9865d83d1740"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in ./.conda/lib/python3.10/site-packages (4.9.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.conda/lib/python3.10/site-packages (4.12.3)\n",
      "Requirement already satisfied: urllib3~=1.26 in ./.conda/lib/python3.10/site-packages (from urllib3[socks]~=1.26->selenium) (1.26.20)\n",
      "Requirement already satisfied: trio~=0.17 in ./.conda/lib/python3.10/site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./.conda/lib/python3.10/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in ./.conda/lib/python3.10/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.conda/lib/python3.10/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: attrs>=23.2.0 in ./.conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in ./.conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in ./.conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in ./.conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in ./.conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in ./.conda/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./.conda/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in ./.conda/lib/python3.10/site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./.conda/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "zQmLv3C_qDRc",
    "outputId": "4593b325-20fe-4591-f975-8aa36817fc85"
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "\n",
    "from typing import List\n",
    "\n",
    "# place_id = \"ChIJ8TuKLOqrQjQRSrGsTe4tu2o\"\n",
    "# place_name = \"Remember Me_記得我．café\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import json\n",
    "import requests\n",
    "from urllib.parse import urlencode\n",
    "import os.path\n",
    "\n",
    "\n",
    "\n",
    "class GoogleCrawler():\n",
    "    def __init__(self):\n",
    "        self.api_key = \"AIzaSyCaXrjbbXaw_s0HJHQi8wJp19QSKL8qMP4\"\n",
    "        self.file_path = \"./places.json\"\n",
    "        # 設置最大評論數量\n",
    "        self.MAX_LEN = 100\n",
    "        self.driver = None\n",
    "\n",
    "    def create_empty_json(self):\n",
    "        data = {}\n",
    "        data[\"places\"] = []\n",
    "        # 建立json檔\n",
    "        with open(self.file_path, \"w\") as file:\n",
    "            json.dump(data, file, indent=4)\n",
    "    def get_all_cafe_by_map(self, query: str = \"台北市的咖啡廳\") -> List[str]:\n",
    "        # 咖啡廳數量\n",
    "        cafe_count = 1500\n",
    "        url = \"https://www.google.com/maps/search/\" + query\n",
    "        self.driver = webdriver.Firefox()\n",
    "        self.driver.get(url)\n",
    "        wait = WebDriverWait(self.driver, 20)  # 增加等待時間\n",
    "        # 滾動整個結果區\n",
    "        try:\n",
    "            pane = wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"m6QErb DxyBCb kA9KIf dS8AEf XiKgde ecceSd\"]')))\n",
    "            for i in range(int(int(cafe_count) / 10)-1):\n",
    "                print(i)\n",
    "                self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", pane)\n",
    "                time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(\"無法找到評論面板:\", e)\n",
    "        #\n",
    "        results = self.driver.find_elements(By.XPATH,f'//a[@class=\"hfpxzc\"]')\n",
    "        return[r.get_attribute('href') for r in results]\n",
    "        self.driver.quit()\n",
    "        self.driver = None\n",
    "\n",
    "    def get_all_cafe(self, url: str = \"https://cafenomad.tw/taipei/list\"):\n",
    "        self.driver = webdriver.Firefox()\n",
    "        self.driver.get(url)\n",
    "        # self.driver.quit()\n",
    "        # self.driver = None\n",
    "\n",
    "    def get_all_cafe_by_place_api(self, query: str = \"台北市的咖啡廳\"):\n",
    "        data = {}\n",
    "        self.create_empty_json()\n",
    "        headers = {\n",
    "            \"Content-Type\": \"application/json\",\n",
    "            \"X-Goog-Api-Key\": self.api_key,\n",
    "            \"X-Goog-FieldMask\": 'places.id,places.displayName,places.formattedAddress,places.regularOpeningHours,places.nationalPhoneNumber,places.rating,places.userRatingCount,places.priceLevel,places.websiteUri,places.allowsDogs,places.reservable,nextPageToken'\n",
    "            # \"X-Goog-FieldMask\": 'places.id,places.displayName,places.formattedAddress,places.regularOpeningHours,places.nationalPhoneNumber,places.rating,places.userRatingCount,places.priceLevel,places.websiteUri,places.allowsDogs,places.reservable,places.reviews,nextPageToken'\n",
    "        }\n",
    "        params = {\n",
    "            \"includedTypes\": [\"cafe\"],\n",
    "            # \"textQuery\" : query,\n",
    "            \"locationRestriction\": {\n",
    "                \"circle\": {\n",
    "                \"center\": {\n",
    "                    \"latitude\": 25.0338,\n",
    "                    \"longitude\": 121.5646 },\n",
    "                \"radius\": 15000.0\n",
    "                }\n",
    "            },\n",
    "            \"languageCode\": \"zh-TW\",\n",
    "        }\n",
    "        # 發送 Nearby Search 請求\n",
    "        search_response = requests.post(\"https://places.googleapis.com/v1/places:searchNearby\", headers=headers, json=params)\n",
    "        search_results = search_response.json()\n",
    "        print(search_results)\n",
    "        \n",
    "        count = 0\n",
    "        while count < 50:\n",
    "            # 取1000筆，每次20筆，共50次\n",
    "            if \"places\" in search_results:\n",
    "                new_data = []\n",
    "                for place in search_results[\"places\"]:\n",
    "                    new_data.append(place)\n",
    "\n",
    "                with open(self.file_path, \"r\") as file:\n",
    "                    data = json.load(file)\n",
    "                    da\n",
    "                    ta[\"places\"].extend(new_data)\n",
    "                with open(self.file_path, \"w\") as file:\n",
    "                    json.dump(data, file, indent=4, ensure_ascii=False)\n",
    "\n",
    "                if \"nextPageToken\" in search_results:\n",
    "                    next_page_token = search_results[\"nextPageToken\"]\n",
    "                    sleep(1.5)  # 避免發送請求速度過快，導致請求失敗\n",
    "                    params[\"pageToken\"] = next_page_token\n",
    "                    search_response = requests.post(\"https://places.googleapis.com/v1/places:searchText\", headers=headers, json=params)\n",
    "                    search_results = search_response.json()\n",
    "                    print(search_results)\n",
    "                else:\n",
    "                    print(\"not next page token\")\n",
    "                    break  # 沒有 Next Page Token，停止迴圈\n",
    "            else:\n",
    "                print(\"No result found.\")\n",
    "                break  # 沒有搜尋結果，停止迴圈\n",
    "        print(\"finish get places.json\")\n",
    "        # self.add_reviews_to_json()\n",
    "    \n",
    "    def add_reviews_to_json(self):\n",
    "        data = {}\n",
    "        self.driver = webdriver.Firefox()\n",
    "        with open(self.file_path, \"r\") as file:      \n",
    "            data = json.load(file)\n",
    "        for place in data[\"places\"]:\n",
    "            id = place[\"id\"]\n",
    "            name = place[\"displayName\"][\"text\"]\n",
    "            time.sleep(2)\n",
    "            reviews = self.get_all_reviews_of_cafe(id, name)\n",
    "            place[\"reviews\"] = reviews\n",
    "        # 關browser\n",
    "        self.driver.quit()\n",
    "        self.driver = None\n",
    "        with open(self.file_path, \"w\") as file:      \n",
    "            json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n",
    "    \n",
    "    def get_all_reviews_of_cafe(self, place_id: str, place_name: str):\n",
    "        if self.driver == None:\n",
    "            print(\"driver not init\")\n",
    "        all_reviews = []\n",
    "        url = \"https://www.google.com/maps/place/?q=place_id:\" + place_id\n",
    "        self.driver.get(url)\n",
    "        wait = WebDriverWait(self.driver, 20)  # 增加等待時間\n",
    "\n",
    "        # 等待評論按鈕並點擊\n",
    "        reviews_btn = wait.until(EC.element_to_be_clickable((By.XPATH, f'//button[@aria-label=\"對「{place_name}」的評論\"]')))\n",
    "        reviews_btn.click()\n",
    "        time.sleep(5)  # 適當等待評論頁面載入\n",
    "\n",
    "        try:\n",
    "            review_num_label = wait.until(EC.visibility_of_element_located((By.XPATH, '//div[@class=\"jANrlb \"][1]//div[@class=\"fontBodySmall\"]')))\n",
    "            time.sleep(1)  # 額外等待\n",
    "            review_num_text = review_num_label.text.split(\" \")[0]\n",
    "            review_num = int(review_num_text.replace(\",\", \"\")) if review_num_text else 0\n",
    "            review_num = min(review_num, self.MAX_LEN)\n",
    "            print(review_num)\n",
    "        except ValueError:\n",
    "            print(\"評論數量無法轉換為整數，請檢查XPATH或等待時間。\")\n",
    "        except Exception as e:\n",
    "            print(\"發生其他錯誤:\", e)\n",
    "\n",
    "        # 滾動評論面板\n",
    "        try:\n",
    "            pane = wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class=\"m6QErb DxyBCb kA9KIf dS8AEf XiKgde \"]')))\n",
    "            for i in range(int(int(review_num) / 10)-1):\n",
    "                self.driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", pane)\n",
    "                time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(\"無法找到評論面板:\", e)\n",
    "\n",
    "        full_btns = self.driver.find_elements(By.XPATH, f'//button[@class=\"w8nwRe kyuRq\"]')\n",
    "        for btn in full_btns:\n",
    "            btn.click()\n",
    "        # 抓取評論區塊\n",
    "        reviewDivs = self.driver.find_elements(By.XPATH, \"//div[@class='jftiEf fontBodyMedium ']\")\n",
    "        all_reviews = []\n",
    "        for review in reviewDivs:\n",
    "            # review_text不一定有\n",
    "            try:\n",
    "                review_text = review.find_element(By.CLASS_NAME, 'MyEned').text\n",
    "            except:\n",
    "                print(\"no review text\")\n",
    "                review_text = \"\"\n",
    "            all_reviews.append(\n",
    "                {\n",
    "                    \"reviewer\": review.find_element(By.CLASS_NAME,'d4r55 ').text,\n",
    "                    \"rating\": review.find_element(By.CLASS_NAME,'kvMYJc').get_attribute('aria-label'),\n",
    "                    \"reviewed_date\": review.find_element(By.CLASS_NAME,'rsqaWe').text,\n",
    "                    \"review_text\": review_text\n",
    "                }\n",
    "            )\n",
    "        print(\"finish\")\n",
    "        return all_reviews\n",
    "crawler = GoogleCrawler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n"
     ]
    }
   ],
   "source": [
    "cafe_ulrs = crawler.get_all_cafe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121\n"
     ]
    }
   ],
   "source": [
    "print(len(cafe_ulrs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crawler.add_reviews_to_json()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4ecZ42R-6xsv"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
